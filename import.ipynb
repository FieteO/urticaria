{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the source data\n",
    "The data is provided as a directory that is three levels deep (the third level is ommited in the following listing).\n",
    "``` bash\n",
    "fiete@ubu:~/Documents/studium/analyse_semi_und_unstrukturierter_daten$ tree -d -L 1 CAPTUM\n",
    "CAPTUM\n",
    "├── Allergic Diseases\n",
    "├── ANA\n",
    "├── Angioedema\n",
    "├── anti-FcεRI\n",
    "├── Antihistamine\n",
    "├── Anti-IgE\n",
    "├── anti-TPO IgE ratio\n",
    "├── ASST\n",
    "├── Basophil\n",
    "├── BAT\n",
    "├── BHRA\n",
    "├── CRP\n",
    "├── Cyclosporine\n",
    "├── D-Dimer\n",
    "├── dsDNA\n",
    "├── Duration\n",
    "├── Eosinophil\n",
    "├── IL-24\n",
    "├── Omalizumab\n",
    "├── Severity\n",
    "├── Thyroglobulin\n",
    "├── Total IgE\n",
    "└── TPO\n",
    "```\n",
    "\n",
    "To work further with the source data, it is useful to have a list of file paths for the pdfs. The following creates a list of all pdf files in the `CAPTUM` source folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['./CAPTUM/CRP/ANA/Asero 2017.pdf',\n",
       " './CAPTUM/CRP/ANA/Magen 2015.pdf',\n",
       " './CAPTUM/CRP/Severity/Kolkhir 2017 .pdf',\n",
       " './CAPTUM/CRP/Severity/Baek 2014.pdf',\n",
       " './CAPTUM/CRP/Severity/Kasperska-Zajac 2015.pdf']"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = './CAPTUM'\n",
    "\n",
    "pdf_filepaths = []\n",
    "for root, directories, files in os.walk(path, topdown=False):\n",
    "\tfor name in files:\n",
    "\t\tpdf_filepaths.append(os.path.join(root, name))\n",
    "\n",
    "pdf_filepaths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data for duplicate entries\n",
    "We can identify duplicate pdfs by computing the checksum of each file and then counting the unique values. So let us define the checksum function `get_checksum()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/16874598/how-do-i-calculate-the-md5-checksum-of-a-file-in-python#16876405\n",
    "import hashlib\n",
    "\n",
    "def get_checksum(filepath: str) -> str:\n",
    "    # Open,close, read file and calculate MD5 on its contents \n",
    "    with open(filepath, 'rb') as file_to_check:\n",
    "        # read contents of the file\n",
    "        data = file_to_check.read()    \n",
    "        # pipe contents of the file through\n",
    "        return hashlib.md5(data).hexdigest()\n",
    "\n",
    "# check that it works\n",
    "file_one, file_one_copy, file_two = \"./pdf_1.pdf\", \"./pdf_1 copy.pdf\", \"./pdf_2.pdf\"\n",
    "assert get_checksum(file_one) == get_checksum(file_one_copy), \"should be equal\"\n",
    "assert get_checksum(file_one) != get_checksum(file_two), \"should not be equal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can create a pandas dataframe from the list of filepath's and also add a checksum column that is computed using our `get_checksum()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               filepath  \\\n",
       "0                       ./CAPTUM/CRP/ANA/Asero 2017.pdf   \n",
       "1                       ./CAPTUM/CRP/ANA/Magen 2015.pdf   \n",
       "2               ./CAPTUM/CRP/Severity/Kolkhir 2017 .pdf   \n",
       "3                   ./CAPTUM/CRP/Severity/Baek 2014.pdf   \n",
       "4        ./CAPTUM/CRP/Severity/Kasperska-Zajac 2015.pdf   \n",
       "...                                                 ...   \n",
       "1054  ./CAPTUM/Omalizumab/Cyclosporine/Rosenblum 202...   \n",
       "1055  ./CAPTUM/Omalizumab/Cyclosporine/Gimenez Arnau...   \n",
       "1056    ./CAPTUM/Omalizumab/Cyclosporine/Koski 2017.pdf   \n",
       "1057       ./CAPTUM/Omalizumab/Cyclosporine/Ke 2017.pdf   \n",
       "1058                          ./CAPTUM/table final .pdf   \n",
       "\n",
       "                              checksum  \n",
       "0     2fad223ae2232cb9e855d3ece9e34b72  \n",
       "1     c721aaea67a47811324b3c860dde612b  \n",
       "2     aed2cb292fdffefe2a319b9d7e517bb3  \n",
       "3     989e3eca08259c9a898acc551473f55f  \n",
       "4     2ed156f4fd5cfa00198f3f6f590940e0  \n",
       "...                                ...  \n",
       "1054  fb22292adf8f35656fde0e54dc0cee51  \n",
       "1055  6a5635468c99716fc18b91b7b6ebaeaf  \n",
       "1056  6cfd7540663be0f6d7fb72f776339b71  \n",
       "1057  849adffe6101df0a030cf425f661e1ed  \n",
       "1058  f13be81ffbff55e031a34ef81d43cbff  \n",
       "\n",
       "[1059 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filepath</th>\n      <th>checksum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>./CAPTUM/CRP/ANA/Asero 2017.pdf</td>\n      <td>2fad223ae2232cb9e855d3ece9e34b72</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>./CAPTUM/CRP/ANA/Magen 2015.pdf</td>\n      <td>c721aaea67a47811324b3c860dde612b</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>./CAPTUM/CRP/Severity/Kolkhir 2017 .pdf</td>\n      <td>aed2cb292fdffefe2a319b9d7e517bb3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>./CAPTUM/CRP/Severity/Baek 2014.pdf</td>\n      <td>989e3eca08259c9a898acc551473f55f</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>./CAPTUM/CRP/Severity/Kasperska-Zajac 2015.pdf</td>\n      <td>2ed156f4fd5cfa00198f3f6f590940e0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1054</th>\n      <td>./CAPTUM/Omalizumab/Cyclosporine/Rosenblum 202...</td>\n      <td>fb22292adf8f35656fde0e54dc0cee51</td>\n    </tr>\n    <tr>\n      <th>1055</th>\n      <td>./CAPTUM/Omalizumab/Cyclosporine/Gimenez Arnau...</td>\n      <td>6a5635468c99716fc18b91b7b6ebaeaf</td>\n    </tr>\n    <tr>\n      <th>1056</th>\n      <td>./CAPTUM/Omalizumab/Cyclosporine/Koski 2017.pdf</td>\n      <td>6cfd7540663be0f6d7fb72f776339b71</td>\n    </tr>\n    <tr>\n      <th>1057</th>\n      <td>./CAPTUM/Omalizumab/Cyclosporine/Ke 2017.pdf</td>\n      <td>849adffe6101df0a030cf425f661e1ed</td>\n    </tr>\n    <tr>\n      <th>1058</th>\n      <td>./CAPTUM/table final .pdf</td>\n      <td>f13be81ffbff55e031a34ef81d43cbff</td>\n    </tr>\n  </tbody>\n</table>\n<p>1059 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(pdf_filepaths, columns = ['filepath'])\n",
    "df['checksum'] = df['filepath'].apply(get_checksum)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step, we can analyse the results of this activity. It seems that our available data is in reality only half as large as it initially appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of pdfs: 1059\nTotal number of unique pdfs: 466\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       2fad223ae2232cb9e855d3ece9e34b72\n",
       "1       c721aaea67a47811324b3c860dde612b\n",
       "2       aed2cb292fdffefe2a319b9d7e517bb3\n",
       "3       989e3eca08259c9a898acc551473f55f\n",
       "4       2ed156f4fd5cfa00198f3f6f590940e0\n",
       "                      ...               \n",
       "1054    fb22292adf8f35656fde0e54dc0cee51\n",
       "1055    6a5635468c99716fc18b91b7b6ebaeaf\n",
       "1056    6cfd7540663be0f6d7fb72f776339b71\n",
       "1057    849adffe6101df0a030cf425f661e1ed\n",
       "1058    f13be81ffbff55e031a34ef81d43cbff\n",
       "Name: checksum, Length: 1059, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "print('Total number of pdfs: {}'.format(df['checksum'].count()))\n",
    "print('Total number of unique pdfs: {}'.format(len(df['checksum'].unique())))\n",
    "df['checksum']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a df of unique pdfs by removing duplicate checksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               filepath  \\\n",
       "0                       ./CAPTUM/CRP/ANA/Asero 2017.pdf   \n",
       "1                       ./CAPTUM/CRP/ANA/Magen 2015.pdf   \n",
       "2               ./CAPTUM/CRP/Severity/Kolkhir 2017 .pdf   \n",
       "3                   ./CAPTUM/CRP/Severity/Baek 2014.pdf   \n",
       "4        ./CAPTUM/CRP/Severity/Kasperska-Zajac 2015.pdf   \n",
       "...                                                 ...   \n",
       "1050  ./CAPTUM/Omalizumab/Cyclosporine/Sánchez 2020.pdf   \n",
       "1053     ./CAPTUM/Omalizumab/Cyclosporine/Seth 2016.pdf   \n",
       "1054  ./CAPTUM/Omalizumab/Cyclosporine/Rosenblum 202...   \n",
       "1056    ./CAPTUM/Omalizumab/Cyclosporine/Koski 2017.pdf   \n",
       "1058                          ./CAPTUM/table final .pdf   \n",
       "\n",
       "                              checksum  \n",
       "0     2fad223ae2232cb9e855d3ece9e34b72  \n",
       "1     c721aaea67a47811324b3c860dde612b  \n",
       "2     aed2cb292fdffefe2a319b9d7e517bb3  \n",
       "3     989e3eca08259c9a898acc551473f55f  \n",
       "4     2ed156f4fd5cfa00198f3f6f590940e0  \n",
       "...                                ...  \n",
       "1050  167014bf6002af9c8c62794730d3473e  \n",
       "1053  0bd4ab01b7e3f79ea404da26da3834b1  \n",
       "1054  fb22292adf8f35656fde0e54dc0cee51  \n",
       "1056  6cfd7540663be0f6d7fb72f776339b71  \n",
       "1058  f13be81ffbff55e031a34ef81d43cbff  \n",
       "\n",
       "[466 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filepath</th>\n      <th>checksum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>./CAPTUM/CRP/ANA/Asero 2017.pdf</td>\n      <td>2fad223ae2232cb9e855d3ece9e34b72</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>./CAPTUM/CRP/ANA/Magen 2015.pdf</td>\n      <td>c721aaea67a47811324b3c860dde612b</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>./CAPTUM/CRP/Severity/Kolkhir 2017 .pdf</td>\n      <td>aed2cb292fdffefe2a319b9d7e517bb3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>./CAPTUM/CRP/Severity/Baek 2014.pdf</td>\n      <td>989e3eca08259c9a898acc551473f55f</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>./CAPTUM/CRP/Severity/Kasperska-Zajac 2015.pdf</td>\n      <td>2ed156f4fd5cfa00198f3f6f590940e0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1050</th>\n      <td>./CAPTUM/Omalizumab/Cyclosporine/Sánchez 2020.pdf</td>\n      <td>167014bf6002af9c8c62794730d3473e</td>\n    </tr>\n    <tr>\n      <th>1053</th>\n      <td>./CAPTUM/Omalizumab/Cyclosporine/Seth 2016.pdf</td>\n      <td>0bd4ab01b7e3f79ea404da26da3834b1</td>\n    </tr>\n    <tr>\n      <th>1054</th>\n      <td>./CAPTUM/Omalizumab/Cyclosporine/Rosenblum 202...</td>\n      <td>fb22292adf8f35656fde0e54dc0cee51</td>\n    </tr>\n    <tr>\n      <th>1056</th>\n      <td>./CAPTUM/Omalizumab/Cyclosporine/Koski 2017.pdf</td>\n      <td>6cfd7540663be0f6d7fb72f776339b71</td>\n    </tr>\n    <tr>\n      <th>1058</th>\n      <td>./CAPTUM/table final .pdf</td>\n      <td>f13be81ffbff55e031a34ef81d43cbff</td>\n    </tr>\n  </tbody>\n</table>\n<p>466 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df_unique = df.drop_duplicates(subset=['checksum'])\n",
    "df_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to read the text from the pdfs.   \n",
    "We use aws textract. You need to add the following setup variables from your aws environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Amazon Textract client\n",
    "textract = boto3.client(    \n",
    "    'textract', \n",
    "    region_name=os.getenv('REGION_NAME'), \n",
    "    aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'), \n",
    "    aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    ")"
   ]
  },
  {
   "source": [
    "Now we iterate over each individual file and call AWS Textract to get the file content."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ClientError",
     "evalue": "An error occurred (UnrecognizedClientException) when calling the DetectDocumentText operation: The security token included in the request is invalid.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c2627aa9fc36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Call Amazon Textract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_document_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Bytes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimageBytes\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Print detected text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (UnrecognizedClientException) when calling the DetectDocumentText operation: The security token included in the request is invalid."
     ]
    }
   ],
   "source": [
    "# Iterate over each individual file\n",
    "for index, row in df_unique.iterrows():\n",
    "    path = row['filepath']\n",
    "\n",
    "    # Read document content\n",
    "    with open(path, 'rb') as pdf:\n",
    "        imageBytes = bytearray(pdf.read())\n",
    "\n",
    "    # Call Amazon Textract\n",
    "    response = textract.detect_document_text(Document={'Bytes': imageBytes})\n",
    "\n",
    "    # Print detected text\n",
    "    for item in response[\"Blocks\"]:\n",
    "        if item[\"BlockType\"] == \"LINE\":\n",
    "            print ('\\033[94m' +  item[\"Text\"] + '\\033[0m')\n",
    "    # TODO:\n",
    "    # Find different ways to interact with the result. Read tables. Read Abstract, Contributors, Text, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}