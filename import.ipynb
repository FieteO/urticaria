{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the source data\n",
    "The data is provided as a directory that is three levels deep (the third level is ommited in the following listing).\n",
    "``` bash\n",
    "fiete@ubu:~/Documents/studium/analyse_semi_und_unstrukturierter_daten$ tree -d -L 1 CAPTUM\n",
    "CAPTUM\n",
    "├── Allergic Diseases\n",
    "├── ANA\n",
    "├── Angioedema\n",
    "├── anti-FcεRI\n",
    "├── Antihistamine\n",
    "├── Anti-IgE\n",
    "├── anti-TPO IgE ratio\n",
    "├── ASST\n",
    "├── Basophil\n",
    "├── BAT\n",
    "├── BHRA\n",
    "├── CRP\n",
    "├── Cyclosporine\n",
    "├── D-Dimer\n",
    "├── dsDNA\n",
    "├── Duration\n",
    "├── Eosinophil\n",
    "├── IL-24\n",
    "├── Omalizumab\n",
    "├── Severity\n",
    "├── Thyroglobulin\n",
    "├── Total IgE\n",
    "└── TPO\n",
    "```\n",
    "\n",
    "To work further with the source data, it is useful to have a list of file paths for the pdfs. The following creates a list of all pdf files in the `CAPTUM` source folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = './CAPTUM'\n",
    "\n",
    "pdf_filepaths = []\n",
    "for root, directories, files in os.walk(path, topdown=False):\n",
    "\tfor name in files:\n",
    "\t\tpdf_filepaths.append(os.path.join(root, name))\n",
    "\n",
    "pdf_filepaths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data for duplicate entries\n",
    "We can identify duplicate pdfs by computing the checksum of each file and then counting the unique values. So let us define the checksum function `get_checksum()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/16874598/how-do-i-calculate-the-md5-checksum-of-a-file-in-python#16876405\n",
    "import hashlib\n",
    "\n",
    "def get_checksum(filepath: str) -> str:\n",
    "    # Open,close, read file and calculate MD5 on its contents \n",
    "    with open(filepath, 'rb') as file_to_check:\n",
    "        # read contents of the file\n",
    "        data = file_to_check.read()    \n",
    "        # pipe contents of the file through\n",
    "        return hashlib.md5(data).hexdigest()\n",
    "\n",
    "# check that it works\n",
    "file_one, file_one_copy, file_two = \"./pdf_1.pdf\", \"./pdf_1 copy.pdf\", \"./pdf_2.pdf\"\n",
    "assert get_checksum(file_one) == get_checksum(file_one_copy), \"should be equal\"\n",
    "assert get_checksum(file_one) != get_checksum(file_two), \"should not be equal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can create a pandas dataframe from the list of filepath's and also add a checksum column that is computed using our `get_checksum()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(pdf_filepaths, columns = ['filepath'])\n",
    "df['checksum'] = df['filepath'].apply(get_checksum)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step, we can analyse the results of this activity. It seems that our available data is in reality only half as large as it initially appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Total number of pdfs: {}'.format(df['checksum'].count()))\n",
    "print('Total number of unique pdfs: {}'.format(len(df['checksum'].unique())))\n",
    "df['checksum']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a df of unique pdfs by removing duplicate checksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df.drop_duplicates(subset=['checksum'])\n",
    "df_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to read the text from the pdfs.   \n",
    "We use aws textract. You need to add the following setup variables from your aws environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Amazon Textract client\n",
    "textract = boto3.client(    \n",
    "    'textract', \n",
    "    region_name=os.getenv('REGION_NAME'), \n",
    "    aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'), \n",
    "    aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    ")"
   ]
  },
  {
   "source": [
    "Now we iterate over each individual file and call AWS Textract to get the file content."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Iterate over each individual file\n",
    "for index, row in df_unique.iterrows():\n",
    "    path = row['filepath']\n",
    "),
    "\n",
    "    # Read document content\n",
    "    with open(path, 'rb') as pdf:\n",
    "        imageBytes = bytearray(pdf.read())\n",
    "\n",
    "    # Call Amazon Textract\n",
    "    response = textract.detect_document_text(Document={'Bytes': imageBytes})\n",
    "\n",
    "    # Print detected text\n",
    "    for item in response[\"Blocks\"]:\n",
    "        if item[\"BlockType\"] == \"LINE\":\n",
    "            print ('\\033[94m' +  item[\"Text\"] + '\\033[0m')\n",
    "    # TODO:\n",
    "    # Find different ways to interact with the result. Read tables. Read Abstract, Contributors, Text, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd016c4804bdb106ff1c20fce08b428b6d583aaa8feec9197dd983d90a0fcde2669",
   "display_name": "Python 3.9.2 64-bit ('urticaria': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}